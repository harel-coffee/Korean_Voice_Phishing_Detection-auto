{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "297a6371064289d7",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-06T08:27:39.437188700Z",
     "start_time": "2024-02-06T08:27:36.919055400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-06 17:27:37.292203: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\r\n",
      "2024-02-06 17:27:37.319924: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-02-06 17:27:37.319979: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-02-06 17:27:37.321143: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "2024-02-06 17:27:37.326914: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\r\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n",
      "2024-02-06 17:27:37.916048: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\r\n",
      "2024-02-06 17:27:38.999135: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\n",
      "Your kernel may have been built without NUMA support.\r\n",
      "2024-02-06 17:27:39.036097: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\n",
      "Your kernel may have been built without NUMA support.\r\n",
      "2024-02-06 17:27:39.036176: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\n",
      "Your kernel may have been built without NUMA support.\r\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-james",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worth-transmission",
   "metadata": {
    "executionInfo": {
     "elapsed": 2360,
     "status": "ok",
     "timestamp": 1650012512493,
     "user": {
      "displayName": "Milandu Keith Moussavou Boussougou",
      "userId": "16125998280788005643"
     },
     "user_tz": -540
    },
    "id": "wJWGvzLaj3Y7",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-02-06T08:27:40.680529400Z",
     "start_time": "2024-02-06T08:27:39.441186800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 17:27:39.691077: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-06 17:27:39.716707: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-06 17:27:39.716738: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-06 17:27:39.717353: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-06 17:27:39.722093: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-06 17:27:40.244532: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta, datetime\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import pickle\n",
    "import sys\n",
    "import subprocess\n",
    "from glob import glob\n",
    "import csv\n",
    "import math\n",
    "import codecs\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# EDA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import plotly.express as px\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# NLP & ML \n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix, \n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    fbeta_score,\n",
    "    roc_auc_score,\n",
    "    matthews_corrcoef,\n",
    "    cohen_kappa_score\n",
    ")\n",
    "\n",
    "# DL\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    InputSpec,\n",
    "    Layer, \n",
    "    Input,\n",
    "    Embedding, \n",
    "    Conv1D, \n",
    "    Conv2D, \n",
    "    Bidirectional, \n",
    "    Dense, \n",
    "    Attention,\n",
    "    LSTM, \n",
    "    Activation, \n",
    "    Add, \n",
    "    Flatten, \n",
    "    Concatenate, \n",
    "    concatenate,\n",
    "    Reshape, \n",
    "    Dropout, \n",
    "    SpatialDropout1D, \n",
    "    BatchNormalization,\n",
    "    MaxPooling1D, \n",
    "    MaxPool2D, \n",
    "    GlobalAveragePooling1D, \n",
    "    GlobalMaxPooling1D, \n",
    "    GlobalMaxPool1D\n",
    ")\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping, CSVLogger\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-jacksonville",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Plotting code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "electronic-stopping",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-02-06T08:27:40.693448200Z",
     "start_time": "2024-02-06T08:27:40.690053900Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_values(pc, fmt=\"%.2f\", **kw):\n",
    "    '''\n",
    "    Heatmap with text in each cell with matplotlib's pyplot\n",
    "    Source: https://stackoverflow.com/a/25074150/395857 \n",
    "    By HYRY\n",
    "    '''\n",
    "#     from itertools import izip\n",
    "    pc.update_scalarmappable()\n",
    "    ax = pc.axes# FOR LATEST MATPLOTLIB\n",
    "    \n",
    "    #Use zip BELOW IN PYTHON 3\n",
    "    for p, color, value in zip(pc.get_paths(), pc.get_facecolors(), pc.get_array()):\n",
    "        x, y = p.vertices[:-2, :].mean(0)\n",
    "        if np.all(color[:3] > 0.5):\n",
    "            color = (0.0, 0.0, 0.0)\n",
    "        else:\n",
    "            color = (1.0, 1.0, 1.0)\n",
    "        # ax.text(x, y, fmt % value, ha=\"center\", va=\"center\", color=color, **kw)\n",
    "\n",
    "\n",
    "def cm2inch(*tupl):\n",
    "    '''\n",
    "    Specify figure size in centimeter in matplotlib\n",
    "    Source: https://stackoverflow.com/a/22787457/395857\n",
    "    By gns-ank\n",
    "    '''\n",
    "    inch = 2.54\n",
    "    if type(tupl[0]) == tuple:\n",
    "        return tuple(i/inch for i in tupl[0])\n",
    "    else:\n",
    "        return tuple(i/inch for i in tupl)\n",
    "\n",
    "\n",
    "def heatmap(AUC, title, xlabel, ylabel, xticklabels, yticklabels, figure_width=40, figure_height=20, correct_orientation=False, cmap='RdBu'):\n",
    "    '''\n",
    "    Inspired by:\n",
    "    - https://stackoverflow.com/a/16124677/395857 \n",
    "    - https://stackoverflow.com/a/25074150/395857\n",
    "    '''\n",
    "\n",
    "    # Plot it out\n",
    "    fig, ax = plt.subplots()    \n",
    "    #c = ax.pcolor(AUC, edgecolors='k', linestyle= 'dashed', linewidths=0.2, cmap='RdBu', vmin=0.0, vmax=1.0)\n",
    "    c = ax.pcolor(AUC, edgecolors='k', linestyle= 'dashed', linewidths=0.2, cmap=cmap)\n",
    "\n",
    "    # put the major ticks at the middle of each cell\n",
    "    ax.set_yticks(np.arange(AUC.shape[0]) + 0.5, minor=False)\n",
    "    ax.set_xticks(np.arange(AUC.shape[1]) + 0.5, minor=False)\n",
    "\n",
    "    # set tick labels\n",
    "    #ax.set_xticklabels(np.arange(1,AUC.shape[1]+1), minor=False)\n",
    "    ax.set_xticklabels(xticklabels, minor=False)\n",
    "    ax.set_yticklabels(yticklabels, minor=False)\n",
    "\n",
    "    # set title and x/y labels\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)      \n",
    "    \n",
    "    # save the figure\n",
    "    plt.savefig('reports/' + title + '_' + datetime.now().strftime(\"%Y%m%d_%H-%M-%S\") + '.png', dpi=600, format='png', bbox_inches='tight')\n",
    "    plt.savefig('reports/' + title + '_' + datetime.now().strftime(\"%Y%m%d_%H-%M-%S\") + '.pdf', dpi=600, format='pdf', bbox_inches='tight')\n",
    "\n",
    "    # Remove last blank column\n",
    "    plt.xlim( (0, AUC.shape[1]) )\n",
    "\n",
    "    # Turn off all the ticks\n",
    "    ax = plt.gca()    \n",
    "    for t in ax.xaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "    for t in ax.yaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "\n",
    "    # Add color bar\n",
    "    plt.colorbar(c)\n",
    "\n",
    "    # Add text in each cell \n",
    "    show_values(c)\n",
    "\n",
    "    # Proper orientation (origin at the top left instead of bottom left)\n",
    "    if correct_orientation:\n",
    "        ax.invert_yaxis()\n",
    "        ax.xaxis.tick_top()       \n",
    "\n",
    "    # resize \n",
    "    fig = plt.gcf()\n",
    "    #fig.set_size_inches(cm2inch(40, 20))\n",
    "    #fig.set_size_inches(cm2inch(40*4, 20*4))\n",
    "    fig.set_size_inches(cm2inch(figure_width, figure_height))\n",
    "    \n",
    "\n",
    "#\n",
    "def plot_classification_report(classification_report, title='Classification report ', cmap='RdBu'):\n",
    "    '''\n",
    "    Plot scikit-learn classification report.\n",
    "    Extension based on https://stackoverflow.com/a/31689645/395857 \n",
    "    '''\n",
    "    lines = classification_report.split('\\n')\n",
    "\n",
    "    classes = []\n",
    "    plotMat = []\n",
    "    support = []\n",
    "    class_names = []\n",
    "    for line in lines[2 : (len(lines) - 4)]:\n",
    "        t = line.strip().split()\n",
    "        if len(t) < 2: continue\n",
    "        classes.append(t[0])\n",
    "        v = [float(x) for x in t[1: len(t) - 1]]\n",
    "        support.append(int(t[-1]))\n",
    "        class_names.append(t[0])\n",
    "        print(v)\n",
    "        plotMat.append(v)\n",
    "\n",
    "    print('plotMat: {0}'.format(plotMat))\n",
    "    print('support: {0}'.format(support))\n",
    "\n",
    "    xlabel = 'Metrics'\n",
    "    ylabel = 'Classes'\n",
    "    xticklabels = ['Precision', 'Recall', 'F1-score']\n",
    "    yticklabels = ['{0} ({1})'.format(class_names[idx], sup) for idx, sup  in enumerate(support)]\n",
    "    figure_width = 25\n",
    "    figure_height = len(class_names) + 7\n",
    "    correct_orientation = False\n",
    "    heatmap(np.array(plotMat), title, xlabel, ylabel, xticklabels, yticklabels, figure_width, figure_height, correct_orientation, cmap=cmap)\n",
    "    \n",
    "# Function to plot the training and validation loss and accuracy\n",
    "def plot_loss_accuracy(history, model_name):\n",
    "    # plot the training and validation loss\n",
    "    plt.plot(history.epoch, history.history['loss'], '-o', label='Training_loss')\n",
    "    plt.plot(history.epoch, history.history['val_loss'], '-o', label='Validation_loss')\n",
    "    plt.title(model_name + ' model loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.xlim(left=0)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.savefig('reports/' + model_name + '_loss_metrics_'+ datetime.now().strftime(\"%Y%m%d_%H-%M-%S\") + '.png', dpi=600, format='png', bbox_inches='tight')\n",
    "    plt.savefig('reports/' + model_name + '_loss_metrics_'+ datetime.now().strftime(\"%Y%m%d_%H-%M-%S\") + '.pdf', dpi=600, format='pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # plot the training and validation accuracy\n",
    "    plt.plot(history.epoch, history.history['accuracy'], '-o', label='Training_accuracy')\n",
    "    plt.plot(history.epoch, history.history['val_accuracy'], '-o', label='Validation_accuracy')\n",
    "    plt.title(model_name + ' model accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.xlim(left=0)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.savefig('reports/' + model_name + '_accuracy' + datetime.now().strftime(\"%Y%m%d_%H-%M-%S\") + '.png', dpi=600, format='png', bbox_inches='tight')\n",
    "    plt.savefig('reports/' + model_name + '_accuracy' + datetime.now().strftime(\"%Y%m%d_%H-%M-%S\") + '.pdf', dpi=600, format='pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_class_distribution(data, title):\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    # sns.set(style=\"ticks\")\n",
    "    ax = sns.countplot(x='label', data=data)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    # Annotate the bars with the number of samples\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                    ha='center', va='baseline', fontsize=11, color='black', xytext=(0, 5),\n",
    "                    textcoords='offset points')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304205db0ac0f50e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0e29107b025942",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Vectorization of the datasets\n",
    "Encoding the text data into numerical data for the deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4b353981ed38768",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T08:27:45.690901300Z",
     "start_time": "2024-02-06T08:27:40.957378100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Datasets loaded.\n"
     ]
    }
   ],
   "source": [
    "#load the datasets\n",
    "print('Loading datasets...')\n",
    "train_set= pd.read_csv('datasets/train_set_ready.csv')\n",
    "val_set = pd.read_csv('datasets/val_set_ready.csv')\n",
    "test_set = pd.read_csv('datasets/test_set_ready.csv')\n",
    "\n",
    "# import all augmented dataset\n",
    "train_set_EnKo = pd.read_csv('datasets/train_set_EnKo_ready.csv')\n",
    "train_set_ChKo = pd.read_csv('datasets/train_set_ChKo_ready.csv')\n",
    "train_set_JaKo = pd.read_csv('datasets/train_set_JaKo_ready.csv')\n",
    "train_set_all = pd.read_csv('datasets/train_set_all_ready.csv')\n",
    "\n",
    "print('Datasets loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with nan values in the train_set_JaKo:  Empty DataFrame\n",
      "Columns: [transcript, transcript_cleaned, corpus, corpus_1, label, length, length_cleaned, length_corpus, length_corpus_1]\n",
      "Index: []\n",
      "Rows with nan values in the train_set_all:  Empty DataFrame\n",
      "Columns: [transcript, transcript_cleaned, corpus, corpus_1, label, length, length_cleaned, length_corpus, length_corpus_1]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Print the rows with nan values in the train_set_jaKo and train_set_all then drop them\n",
    "print('Rows with nan values in the train_set_JaKo: ', train_set_JaKo[train_set_JaKo.isna().any(axis=1)])\n",
    "print('Rows with nan values in the train_set_all: ', train_set_all[train_set_all.isna().any(axis=1)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T08:27:46.860118800Z",
     "start_time": "2024-02-06T08:27:46.784830Z"
    }
   },
   "id": "3e36c0f0adf38fe9",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21e6e14d157da4fe",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T08:27:49.268439300Z",
     "start_time": "2024-02-06T08:27:49.231617400Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the train and test sets data from the dataframes\n",
    "X_train = train_set['corpus']\n",
    "X_train_1 = train_set['corpus_1']\n",
    "y_train = train_set['label']\n",
    "\n",
    "X_val = val_set['corpus']\n",
    "X_val_1 = val_set['corpus_1']\n",
    "y_val = val_set['label']\n",
    "\n",
    "X_test = test_set['corpus']\n",
    "X_test_1 = test_set['corpus_1']\n",
    "y_test = test_set['label']\n",
    "\n",
    "X_train_EnKo = train_set_EnKo['corpus']\n",
    "X_train_EnKo_1 = train_set_EnKo['corpus_1']\n",
    "y_train_EnKo = train_set_EnKo['label']\n",
    "\n",
    "X_train_ChKo = train_set_ChKo['corpus']\n",
    "X_train_ChKo_1 = train_set_ChKo['corpus_1']\n",
    "y_train_ChKo = train_set_ChKo['label']\n",
    "\n",
    "X_train_JaKo = train_set_JaKo['corpus']\n",
    "X_train_JaKo_1 = train_set_JaKo['corpus_1']\n",
    "y_train_JaKo = train_set_JaKo['label']\n",
    "\n",
    "X_train_all = train_set_all['corpus']\n",
    "X_train_all_1 = train_set_all['corpus_1']\n",
    "y_train_all = train_set_all['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6c4524f5ef5f343",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T08:27:50.580875500Z",
     "start_time": "2024-02-06T08:27:50.528770Z"
    }
   },
   "outputs": [],
   "source": [
    "# write a function to pick the right augmented dataset to be used for the training\n",
    "def pick_augmented_dataset(augmented_dataset, X_train, X_train_1, y_train):\n",
    "    \"\"\"\n",
    "    Function to pick the right augmented dataset to be used for the training\n",
    "    \n",
    "    Parameters:\n",
    "    augmented_dataset: str, default='default'\n",
    "        The augmented dataset to be used for the training. It can be 'EnKo', 'ChKo', 'JaKo', 'All' or 'default' (original dataset)\n",
    "    X_train: list or array\n",
    "        The original trainset\n",
    "    X_train_1: list or array\n",
    "        The original trainset\n",
    "    y_train: list or array\n",
    "        The original trainset\n",
    "    \"\"\"\n",
    "    if augmented_dataset == 'EnKo':\n",
    "        X_train = X_train_EnKo\n",
    "        X_train_1 = X_train_EnKo_1\n",
    "        y_train = y_train_EnKo\n",
    "        print('Using the EnKo augmented dataset for the training')\n",
    "    elif augmented_dataset == 'ChKo':\n",
    "        X_train = X_train_ChKo\n",
    "        X_train_1 = X_train_ChKo_1\n",
    "        y_train = y_train_ChKo\n",
    "        print('Using the ChKo augmented dataset for the training')\n",
    "    elif augmented_dataset == 'JaKo':\n",
    "        X_train = X_train_JaKo\n",
    "        X_train_1 = X_train_JaKo_1\n",
    "        y_train = y_train_JaKo\n",
    "        print('Using the JaKo augmented dataset for the training')\n",
    "    elif augmented_dataset == 'All':\n",
    "        X_train = X_train_all\n",
    "        X_train_1 = X_train_all_1\n",
    "        y_train = y_train_all\n",
    "        print('Using the All augmented dataset for the training')\n",
    "    else:\n",
    "        X_train = X_train\n",
    "        X_train_1 = X_train_1\n",
    "        y_train = y_train\n",
    "        print('Using the original dataset for the training')\n",
    "    return X_train, X_train_1, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9951f1b56dd444f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T08:27:52.308038700Z",
     "start_time": "2024-02-06T08:27:52.257527400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the JaKo augmented dataset for the training\n"
     ]
    }
   ],
   "source": [
    "# pick the right augmented dataset to be used for the training\n",
    "augmented_dataset = 'JaKo' # 'EnKo', 'ChKo', 'JaKo', 'All' or 'default\n",
    "X_train, X_train_1, y_train = pick_augmented_dataset(augmented_dataset, X_train, X_train_1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c295ae7fb961a7d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T08:27:53.737492900Z",
     "start_time": "2024-02-06T08:27:53.683491200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to define the maximum number of words to be used\n",
    "def max_words_func(X_train, X_val, X_test):\n",
    "    max_len = 0\n",
    "    max_words = 0\n",
    " \n",
    "    # check the length of the trainset, the valset and the testset\n",
    "    print('Train set size = {} \\nValidation set size = {} \\nTest set size = {}'.format(len(X_train), len(X_val), len(X_test)))\n",
    "    \n",
    "    # count the maximum number of words in the trainset\n",
    "    max_words = len(set(\" \".join(X_train).split())) # max number of words for tokenizer\n",
    "    print('Maximum number of words in the train set = {}'.format(max_words))\n",
    "    \n",
    "    # get the maximum length of the sentences in the trainset\n",
    "    max_len = max([len(x.split()) for x in X_train]) # max length of each sentences, including padding\n",
    "    print('Maximum length of a sentence in the train set = {}'.format(max_len))\n",
    "\n",
    "    return max_words, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72f2f23593ed4252",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T08:27:55.266521100Z",
     "start_time": "2024-02-06T08:27:55.182498500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size = 2531 \n",
      "Validation set size = 440 \n",
      "Test set size = 440\n",
      "Maximum number of words in the train set = 34249\n",
      "Maximum length of a sentence in the train set = 4715\n"
     ]
    }
   ],
   "source": [
    "# define the maximum number of words and the maximum length of the sentences in the trainset\n",
    "max_words, max_len = max_words_func(X_train, X_val, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a30a4d36047d5035",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T08:27:57.435642900Z",
     "start_time": "2024-02-06T08:27:57.307354700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(s) for s in X_train], bins=20)\n",
    "plt.xlabel('Length of Data')\n",
    "plt.ylabel('Number of Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e33ddd44583ca683",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T08:27:58.679783800Z",
     "start_time": "2024-02-06T08:27:58.596425500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(s) for s in X_test], bins=20)\n",
    "plt.xlabel('Length of Data')\n",
    "plt.ylabel('Number of Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f416c15395795df",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Traininig with the original train_set dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e659a18a85f818",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to tokenize the text data\n",
    "def tokenize_text(X_train, X_val, X_test, max_words=max_words, max_len=max_len):\n",
    "    # define the tokenizer and tokenization\n",
    "    tokenizer = Tokenizer(num_words=max_words, lower=False, char_level=False)\n",
    "    tokenizer.fit_on_texts(X_train)  #leaky\n",
    "    \n",
    "    # Function to convert texts to sequences of integers\n",
    "    def texts_to_sequences(X_train, X_val, X_test):\n",
    "        # convert texts to sequences of integers\n",
    "        X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "        X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "        X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "        word_index = tokenizer.word_index\n",
    "        \n",
    "        print(\"Dictionary size: \", len(word_index))\n",
    "        \n",
    "        return X_train_seq, X_val_seq, X_test_seq, word_index\n",
    "    \n",
    "    # define the sequences of integers\n",
    "    X_train_seq, X_val_seq, X_test_seq, word_index = texts_to_sequences(X_train, X_val, X_test)\n",
    "    \n",
    "    # FPad the sequences to ensure uniform length\n",
    "    X_train_pad = pad_sequences(X_train_seq, padding='pre', maxlen=max_len)\n",
    "    X_val_pad = pad_sequences(X_val_seq, padding='pre', maxlen=max_len)\n",
    "    X_test_pad = pad_sequences(X_test_seq, padding='pre', maxlen=max_len)\n",
    "    \n",
    "    return X_train_pad, X_val_pad, X_test_pad, word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b10bf5ddd0fc1a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tokenize the text data\n",
    "X_train_pad, X_val_pad, X_test_pad, word_index = tokenize_text(X_train, X_val, X_test, max_words, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356f63c9492ba87e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Model Building and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b70dd5195612f20",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Importing the FastText word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357614d51612fad7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run if the wiki.ko.vec is not available in the same directory\n",
    "import os\n",
    "import urllib.request\n",
    "# check if the file wiki.ko.vec is in the directory if not download it\n",
    "if not os.path.isfile('wiki.ko.vec'):\n",
    "    print('wiki.ko.vec does not exist, downloading file from the internet')\n",
    "    # download the FastText word embeddings and monitor the download progress bar with tqdm\n",
    "    with tqdm(unit='B', unit_scale=True, miniters=1, desc='wiki.ko.vec') as t:\n",
    "        urllib.request.urlretrieve('https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.ko.vec', 'wiki.ko.vec', reporthook=lambda a,b,c: t.update(c))\n",
    "    # urllib.request.urlretrieve('https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.ko.vec', 'wiki.ko.vec')\n",
    "else:\n",
    "    print('wiki.ko.vec exists, will not download file from the internet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a103be30767f56",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the FastText word embeddings\n",
    "print('Loading word FastText embeddings...')\n",
    "embeddings_index = {}\n",
    "f = codecs.open('wiki.ko.vec', encoding='utf-8')\n",
    "\n",
    "for line in tqdm(f):\n",
    "    values = line.rstrip().rsplit(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79507de0f1a4c06",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Found %s word vectors' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5951bee5a0d0fcf3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the preprocessing parameters\n",
    "embedding_dim = 300 # embedding dimensions for word vectors (word2vec/GloVe/Fasttext)\n",
    "\n",
    "# defining the hyperparameters\n",
    "learning_rate = 1e-3\n",
    "batch_size= 32 # 64, 128\n",
    "epochs = 10\n",
    "steps_per_epoch = len(X_train) // batch_size  # total_samples is the training set size\n",
    "\n",
    "# Calculating decay steps\n",
    "# It's common to decay the learning rate at each epoch\n",
    "decay_steps = steps_per_epoch * epochs # 10000\n",
    "decay_rate = 0.9  # This is a common decay rate, but you can adjust it\n",
    "# learning_decay = 1e-10 # 1e-4\n",
    "\n",
    "spa_dropout_ratio = 0.2 # dropout ration, dropping a entire feature map\n",
    "kernel_size = 3 # [1,2,3,5] # [1,2,3,5] Size of the kernel. Mixing kernels of various sizes.\n",
    "                # specifying the length of the 1D convolution window.\n",
    "dense_units = 64 # hidden unit 128 the number of neurons in the hidden layer\n",
    "dropout_ratio = 0.2 # 0.1, 0.2 to 0.5 Dropout Ratio\n",
    "num_filters = 50 # 36, 128, 256 number of kernels, conv_size\n",
    "                # Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n",
    "\n",
    "lstm_units_1 = 64 # the size(dim) of the hidden state vector as well as the output vector.\n",
    "lstm_units_2 = 32 # the size(dim) of the hidden state vector as well as the output vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bded3c2c7b7c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Preparing FastText embedding matrix for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f18cf14ef79ccfc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#embedding matrix\n",
    "# print('Preparing embedding matrix for future use...')\n",
    "words_not_found = []\n",
    "embed_dim = embedding_dim #300 # 32 Dimensions of the embedding vector\n",
    "nb_words = min(max_words, len(word_index))\n",
    "embedding_matrix = np.zeros((max_words, embed_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= nb_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        words_not_found.append(word)\n",
    "print('number of null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
    "print(\"sample words not found: \", np.random.choice(words_not_found, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3150406220c6a16",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting up our results dataframe\n",
    "df_results = pd.DataFrame(columns=['F1_score', 'Precision', 'Recall', 'Accuracy', 'Training time'])\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dabfd8c5ab6c0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Training with default embedding layer and the original train_set dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76aec593e9c1704",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Single LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda6204c1c043e69",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write a function to build, train and evaluate the LSTM model\n",
    "def build_train_lstm_model(model_name, X_train, y_train, X_val, y_val, X_test, y_test, epochs=epochs, batch_size=batch_size, learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate, embedding_matrix=None):\n",
    "    \n",
    "    # define the model architecture\n",
    "    model = Sequential()\n",
    "    # check if the embedding_matrix is None or not\n",
    "    if embedding_matrix is None:\n",
    "        model.add(Embedding(max_words, embedding_dim, input_length=max_len, trainable=False))\n",
    "    else:\n",
    "        model.add(Embedding(max_words, embedding_dim, weights= [embedding_matrix], input_length=max_len, trainable=False))\n",
    "    # model.add(SpatialDropout1D(spa_dropout_ratio))\n",
    "    model.add(LSTM(lstm_units_1))\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    # model.add(LSTM(lstm_units_1, dropout=dropout_ratio, recurrent_dropout=dropout_ratio))\n",
    "    model.add(Dropout(dropout_ratio))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification\n",
    "    \n",
    "    # compile the model\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=learning_rate,\n",
    "    decay_steps=decay_steps,\n",
    "    decay_rate=decay_rate\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        # optimizer=Adam(learning_rate=learning_rate, decay=learning_rate / decay_steps),\n",
    "        optimizer = Adam(learning_rate=lr_schedule),\n",
    "        loss='binary_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # print the model summary\n",
    "    print(model.summary())\n",
    "    print('#' * 150)\n",
    "    \n",
    "    # Create a callback that saves the best model during validation\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        \"models/\" + model_name + \"_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \".h5\",\n",
    "        # \"models/LSTM_\"+ datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \".h5\",\n",
    "        monitor='val_accuracy', # val_loss or val_accuracy \n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='max' # max for val_accuracy, min for val_loss\n",
    "    )\n",
    "    # EarlyStopping to stop training when the validation loss has stopped improving\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        verbose = 1,\n",
    "        patience = 3, # Number of epochs with no improvement after which training will be stopped.\n",
    "        mode = 'min'\n",
    "    )\n",
    "\n",
    "    # TensorBoard for visualization\n",
    "    log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    # train the model\n",
    "    start_time = time()\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1,\n",
    "        callbacks=[model_checkpoint, early_stopping, tensorboard_callback]\n",
    "    )\n",
    "    end_time = time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    # print the training time\n",
    "    print('Training time: {}'.format(training_time))\n",
    "    \n",
    "    # evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print('Test Loss: {}'.format(loss))\n",
    "    print('Test Accuracy: {}'.format(accuracy))\n",
    "    \n",
    "    # predict the test set\n",
    "    # y_pred = model.predict(X_test)\n",
    "    # y_pred = np.argmax(y_pred, axis=1)\n",
    "    # y_test = np.argmax(y_test, axis=1)\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred = (y_pred_probs >= 0.5).astype(int)  # Convert probabilities to binary (0 or 1)\n",
    "    \n",
    "    # print the precision, recall and f1-score\n",
    "    model_precision = precision_score(y_test, y_pred)\n",
    "    model_recall = recall_score(y_test, y_pred)\n",
    "    model_f1_score = f1_score(y_test, y_pred)\n",
    "    print('Precision: {}'.format(model_precision))\n",
    "    print('Recall: {}'.format(model_recall))\n",
    "    print('F1-score: {}'.format(model_f1_score))\n",
    "        \n",
    "    # print the classification report\n",
    "    report = classification_report(y_test, y_pred, digits=4, target_names=['None_vishing', 'Vishing'])\n",
    "    print(report)\n",
    "    \n",
    "    # print the confusion matrix\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "        \n",
    "    # save the model\n",
    "    # model.save('models/{}.h5'.format(model_name))\n",
    "    \n",
    "    # save the history\n",
    "    with open('histories/{}.pkl'.format(model_name), 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "    \n",
    "    # save the results\n",
    "    df_results.loc[model_name] = [model_f1_score, model_precision, model_recall, accuracy, training_time]\n",
    "    # df_results.loc[model_name] = [f1_score(y_test, y_pred), precision_score(y_test, y_pred), recall_score(y_test, y_pred), accuracy, training_time]  \n",
    "    \n",
    "    # print the results\n",
    "    # df_results\n",
    "    \n",
    "    return model, history, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2017516f93ef4f8",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build, train and evaluate the LSTM model\n",
    "model_name = augmented_dataset + '_LSTM'\n",
    "model_lstm, history_lstm, report_lstm = build_train_lstm_model(model_name, X_train_pad, y_train, X_val_pad, y_val, X_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0ca2bfe3338c02",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41f51391066c0e2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625c0810be4efd9d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_name = augmented_dataset + '_LSTM_Classification_report'\n",
    "plot_classification_report(report_lstm, plot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c42da799e8a2e80",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the training and validation loss and accuracy\n",
    "plot_name = augmented_dataset + '_LSTM'\n",
    "plot_loss_accuracy(history_lstm, plot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95166221fd87fe2e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the tensorboard results\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir logs/fit\n",
    "# %tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1caeff66dd045e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Single LSTM layer with FastText embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c831bd3c3b085ae",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build, train and evaluate the LSTM model\n",
    "model_name = augmented_dataset + '_LSTM_FT'\n",
    "model_lstm_ft, history_lstm_ft, report_lstm_ft = build_train_lstm_model(model_name, X_train_pad, y_train, X_val_pad, y_val, X_test_pad, y_test, embedding_matrix=embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b986a90fcc29a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f9b8ad4eda3151",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_name = augmented_dataset + '_LSTM_FT_Classification_report'\n",
    "plot_classification_report(report_lstm_ft, plot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b77062be8ac33f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the training and validation loss and accuracy\n",
    "plot_name = augmented_dataset + '_LSTM_FT'\n",
    "plot_loss_accuracy(history_lstm_ft, plot_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba9dfd0ee4f6361",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Stacked LSTM layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e57ec3571bc44f1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write a function to build, train and evaluate the LSTM model\n",
    "def build_train_stackedlstm_model(model_name, X_train, y_train, X_val, y_val, X_test, y_test, epochs=epochs, batch_size=batch_size, learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate, embedding_matrix=None):\n",
    "    \n",
    "    # define the model architecture\n",
    "    model = Sequential()\n",
    "    # check if the embedding_matrix is None or not\n",
    "    if embedding_matrix is None:\n",
    "        model.add(Embedding(max_words, embedding_dim, input_length=max_len, trainable=False))\n",
    "    else:\n",
    "        model.add(Embedding(max_words, embedding_dim, weights= [embedding_matrix], input_length=max_len, trainable=False))\n",
    "    \n",
    "    # model.add(SpatialDropout1D(spa_dropout_ratio))\n",
    "    model.add(LSTM(lstm_units_1, return_sequences=True))\n",
    "    model.add(LSTM(lstm_units_2))\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    # model.add(LSTM(lstm_units_1, dropout=dropout_ratio, recurrent_dropout=dropout_ratio))\n",
    "    model.add(Dropout(dropout_ratio))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification\n",
    "    \n",
    "    # compile the model\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=learning_rate,\n",
    "    decay_steps=decay_steps,\n",
    "    decay_rate=decay_rate\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        # optimizer=Adam(learning_rate=learning_rate, decay=learning_rate / decay_steps),\n",
    "        optimizer = Adam(learning_rate=lr_schedule),\n",
    "        loss='binary_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # print the model summary\n",
    "    print(model.summary())\n",
    "    print('#' * 150)\n",
    "    \n",
    "    # Create a callback that saves the best model during validation\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        \"models/\" + model_name + \"_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \".h5\",\n",
    "        monitor='val_accuracy', # val_loss or val_accuracy \n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='max' # max for val_accuracy, min for val_loss\n",
    "    )\n",
    "    # EarlyStopping to stop training when the validation loss has stopped improving\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        verbose = 1,\n",
    "        patience = 3, # Number of epochs with no improvement after which training will be stopped.\n",
    "        mode = 'min'\n",
    "    )\n",
    "\n",
    "    # TensorBoard for visualization\n",
    "    log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    # train the model\n",
    "    start_time = time()\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1,\n",
    "        callbacks=[model_checkpoint, early_stopping, tensorboard_callback]\n",
    "    )\n",
    "    end_time = time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    # print the training time\n",
    "    print('Training time: {}'.format(training_time))\n",
    "    \n",
    "    # evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print('Test Loss: {}'.format(loss))\n",
    "    print('Test Accuracy: {}'.format(accuracy))\n",
    "    \n",
    "    # predict the test set\n",
    "    # y_pred = model.predict(X_test)\n",
    "    # y_pred = np.argmax(y_pred, axis=1)\n",
    "    # y_test = np.argmax(y_test, axis=1)\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred = (y_pred_probs >= 0.5).astype(int)  # Convert probabilities to binary (0 or 1)\n",
    "    \n",
    "    # print the precision, recall and f1-score\n",
    "    model_precision = precision_score(y_test, y_pred)\n",
    "    model_recall = recall_score(y_test, y_pred)\n",
    "    model_f1_score = f1_score(y_test, y_pred)\n",
    "    print('Precision: {}'.format(model_precision))\n",
    "    print('Recall: {}'.format(model_recall))\n",
    "    print('F1-score: {}'.format(model_f1_score))\n",
    "        \n",
    "    # print the classification report\n",
    "    report = classification_report(y_test, y_pred, digits=4, target_names=['None_vishing', 'Vishing'])\n",
    "    print(report)\n",
    "    \n",
    "    # print the confusion matrix\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "        \n",
    "    # save the model\n",
    "    # model.save('models/{}.h5'.format(model_name))\n",
    "    \n",
    "    # save the history\n",
    "    with open('histories/{}.pkl'.format(model_name), 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "    \n",
    "    # save the results\n",
    "    df_results.loc[model_name] = [model_f1_score, model_precision, model_recall, accuracy, training_time]\n",
    "    # df_results.loc[model_name] = [f1_score(y_test, y_pred), precision_score(y_test, y_pred), recall_score(y_test, y_pred), accuracy, training_time]  \n",
    "    \n",
    "    # print the results\n",
    "    # df_results\n",
    "    \n",
    "    return model, history, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6249804883bea896",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build, train and evaluate the stacked LSTM layers model\n",
    "model_name = augmented_dataset + '_stackedLSTM'\n",
    "model_stackedlstm, history_stackedlstm, report_stackedlstm = build_train_stackedlstm_model(model_name, X_train_pad, y_train, X_val_pad, y_val, X_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8390b4bf4d8d6b75",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114dba2a27540cea",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_name = augmented_dataset + '_stackedLSTM_Classification_report'\n",
    "plot_classification_report(report_stackedlstm, plot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc0e4d9b8db2b78",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the training and validation loss and accuracy\n",
    "plot_name = augmented_dataset + '_stackedLSTM'\n",
    "plot_loss_accuracy(history_stackedlstm, plot_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4bf5de70aad18d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Stacked LSTM layer with FastText embedding layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba82e22db70417",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build, train and evaluate the stacked LSTM layers model with FastText embedding layer\n",
    "model_name = augmented_dataset + '_stackedLSTM_FT'\n",
    "model_stackedlstm_ft, history_stackedlstm_ft, report_stackedlstm_ft = build_train_stackedlstm_model(model_name, X_train_pad, y_train, X_val_pad, y_val, X_test_pad, y_test, embedding_matrix=embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac013f720a88e7c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453c8bd4ab21c03d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the confusion matrix\n",
    "plot_name = augmented_dataset + '_stackedLSTM_FT_Classification_report'\n",
    "plot_classification_report(report_stackedlstm_ft, plot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9ce8b183276be6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the training and validation loss and accuracy\n",
    "plot_name = augmented_dataset + '_stackedLSTM_FT'\n",
    "plot_loss_accuracy(history_stackedlstm_ft, plot_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81668053c0331c9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Single BiLSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f81b5925a0b1f1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to build, train and evaluate the BiLSTM model\n",
    "def build_train_bilstm_model(model_name, X_train, y_train, X_val, y_val, X_test, y_test, epochs=epochs, batch_size=batch_size, learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate, embedding_matrix=None):\n",
    "    \n",
    "    # define the model architecture\n",
    "    model = Sequential()\n",
    "    # check if the embedding_matrix is None or not\n",
    "    if embedding_matrix is None:\n",
    "        model.add(Embedding(max_words, embedding_dim, input_length=max_len, trainable=False))\n",
    "    else:\n",
    "        model.add(Embedding(max_words, embedding_dim, weights= [embedding_matrix], input_length=max_len, trainable=False))\n",
    "    \n",
    "    # model.add(SpatialDropout1D(spa_dropout_ratio))\n",
    "    model.add(Bidirectional(LSTM(lstm_units_1)))\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    model.add(Dropout(dropout_ratio))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification\n",
    "    \n",
    "    # compile the model\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=learning_rate,\n",
    "    decay_steps=decay_steps,\n",
    "    decay_rate=decay_rate\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        # optimizer=Adam(learning_rate=learning_rate, decay=learning_rate / decay_steps),\n",
    "        optimizer = Adam(learning_rate=lr_schedule),\n",
    "        loss='binary_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # print the model summary\n",
    "    print(model.summary())\n",
    "    print('#' * 150)\n",
    "    \n",
    "    # Create a callback that saves the best model during validation\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        \"models/\" + model_name + \"_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \".h5\",\n",
    "        # \"models/BiLSTM_\"+ datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \".h5\",\n",
    "        monitor='val_accuracy', # val_loss or val_accuracy \n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='max' # max for val_accuracy, min for val_loss\n",
    "    )\n",
    "    # EarlyStopping to stop training when the validation loss has stopped improving\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        verbose = 1,\n",
    "        patience = 3, # Number of epochs with no improvement after which training will be stopped.\n",
    "        mode = 'min'\n",
    "    )\n",
    "\n",
    "    # TensorBoard for visualization\n",
    "    log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    # train the model\n",
    "    start_time = time()\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1,\n",
    "        callbacks=[model_checkpoint, early_stopping, tensorboard_callback]\n",
    "    )\n",
    "    end_time = time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    # print the training time\n",
    "    print('Training time: {}'.format(training_time))\n",
    "    \n",
    "    # evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print('Test Loss: {}'.format(loss))\n",
    "    print('Test Accuracy: {}'.format(accuracy))\n",
    "    \n",
    "    # predict the test set\n",
    "    # y_pred = model.predict(X_test)\n",
    "    # y_pred = np.argmax(y_pred, axis=1)\n",
    "    # y_test = np.argmax(y_test, axis=1)\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred = (y_pred_probs >= 0.5).astype(int)  # Convert probabilities to binary (0 or 1)\n",
    "    \n",
    "    # print the precision, recall and f1-score\n",
    "    model_precision = precision_score(y_test, y_pred)\n",
    "    model_recall = recall_score(y_test, y_pred)\n",
    "    model_f1_score = f1_score(y_test, y_pred)\n",
    "    print('Precision: {}'.format(model_precision))\n",
    "    print('Recall: {}'.format(model_recall))\n",
    "    print('F1-score: {}'.format(model_f1_score))\n",
    "        \n",
    "    # print the classification report\n",
    "    report = classification_report(y_test, y_pred, digits=4, target_names=['None_vishing', 'Vishing'])\n",
    "    print(report)\n",
    "    \n",
    "    # print the confusion matrix\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "        \n",
    "    # save the model\n",
    "    # model.save('models/{}.h5'.format(model_name))\n",
    "    \n",
    "    # save the history\n",
    "    with open('histories/{}.pkl'.format(model_name), 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "    \n",
    "    # save the results\n",
    "    df_results.loc[model_name] = [model_f1_score, model_precision, model_recall, accuracy, training_time]\n",
    "    # df_results.loc[model_name] = [f1_score(y_test, y_pred), precision_score(y_test, y_pred), recall_score(y_test, y_pred), accuracy, training_time]  \n",
    "    \n",
    "    # print the results\n",
    "    # df_results\n",
    "    \n",
    "    return model, history, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edaf34fad9548",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build, train and evaluate the BiLSTM model\n",
    "model_name = augmented_dataset + '_BiLSTM'\n",
    "model_bilstm, history_bilstm, report_bilstm = build_train_bilstm_model(model_name, X_train_pad, y_train, X_val_pad, y_val, X_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e255abfe8d64e4f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e325f64cf221a87",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the confusion matrix\n",
    "plot_name = augmented_dataset + '_BiLSTM_Classification_report'\n",
    "plot_classification_report(report_bilstm, plot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15853e33f406f5e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the training and validation loss and accuracy\n",
    "plot_name = augmented_dataset + '_BiLSTM'\n",
    "plot_loss_accuracy(history_bilstm, plot_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1378386f859f9376",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Single BiLSTM layer with FastText embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a8ad2745658e79",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build, train and evaluate the BiLSTM model with FastText embedding layer\n",
    "model_name = augmented_dataset + '_BiLSTM_FT'\n",
    "model_bilstm_ft, history_bilstm_ft, report_bilstm_ft = build_train_bilstm_model(model_name, X_train_pad, y_train, X_val_pad, y_val, X_test_pad, y_test, embedding_matrix=embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa40985a53025335",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f5e5e6ce1ed095",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the confusion matrix\n",
    "plot_name = augmented_dataset + '_BiLSTM_FT_Classification_report'\n",
    "plot_classification_report(report_bilstm_ft, plot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f295141d753556a4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the training and validation loss and accuracy\n",
    "plot_name = augmented_dataset + '_BiLSTM_FT'\n",
    "plot_loss_accuracy(history_bilstm_ft, plot_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bda6f2ca02c14e9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Stacked BiLSTM layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79dec586d42447e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to build, train and evaluate the stacked BiLSTM model\n",
    "def build_train_stackedbilstm_model(model_name, X_train, y_train, X_val, y_val, X_test, y_test, epochs=epochs, batch_size=batch_size, learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate, embedding_matrix=None):\n",
    "    \n",
    "    # define the model architecture\n",
    "    model = Sequential()\n",
    "    # check if the embedding_matrix is None or not\n",
    "    if embedding_matrix is None:\n",
    "        model.add(Embedding(max_words, embedding_dim, input_length=max_len, trainable=False))\n",
    "    else:\n",
    "        model.add(Embedding(max_words, embedding_dim, weights= [embedding_matrix], input_length=max_len, trainable=False))\n",
    "    \n",
    "    # model.add(SpatialDropout1D(spa_dropout_ratio))\n",
    "    model.add(Bidirectional(LSTM(lstm_units_1,return_sequences=True)))\n",
    "    model.add(Bidirectional(LSTM(lstm_units_2)))\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    model.add(Dropout(dropout_ratio))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification\n",
    "    \n",
    "    # compile the model\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=learning_rate,\n",
    "    decay_steps=decay_steps,\n",
    "    decay_rate=decay_rate\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        # optimizer=Adam(learning_rate=learning_rate, decay=learning_rate / decay_steps),\n",
    "        optimizer = Adam(learning_rate=lr_schedule),\n",
    "        loss='binary_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # print the model summary\n",
    "    print(model.summary())\n",
    "    print('#' * 150)\n",
    "    \n",
    "    # Create a callback that saves the best model during validation\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        \"models/\" + model_name + \"_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \".h5\",\n",
    "        # \"models/BiLSTM_\"+ datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \".h5\",\n",
    "        monitor='val_accuracy', # val_loss or val_accuracy \n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='max' # max for val_accuracy, min for val_loss\n",
    "    )\n",
    "    # EarlyStopping to stop training when the validation loss has stopped improving\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        verbose = 1,\n",
    "        patience = 3, # Number of epochs with no improvement after which training will be stopped.\n",
    "        mode = 'min'\n",
    "    )\n",
    "\n",
    "    # TensorBoard for visualization\n",
    "    log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    # train the model\n",
    "    start_time = time()\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1,\n",
    "        callbacks=[model_checkpoint, early_stopping, tensorboard_callback]\n",
    "    )\n",
    "    end_time = time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    # print the training time\n",
    "    print('Training time: {}'.format(training_time))\n",
    "    \n",
    "    # evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print('Test Loss: {}'.format(loss))\n",
    "    print('Test Accuracy: {}'.format(accuracy))\n",
    "    \n",
    "    # predict the test set\n",
    "    # y_pred = model.predict(X_test)\n",
    "    # y_pred = np.argmax(y_pred, axis=1)\n",
    "    # y_test = np.argmax(y_test, axis=1)\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred = (y_pred_probs >= 0.5).astype(int)  # Convert probabilities to binary (0 or 1)\n",
    "    \n",
    "    # print the precision, recall and f1-score\n",
    "    model_precision = precision_score(y_test, y_pred)\n",
    "    model_recall = recall_score(y_test, y_pred)\n",
    "    model_f1_score = f1_score(y_test, y_pred)\n",
    "    print('Precision: {}'.format(model_precision))\n",
    "    print('Recall: {}'.format(model_recall))\n",
    "    print('F1-score: {}'.format(model_f1_score))\n",
    "        \n",
    "    # print the classification report\n",
    "    report = classification_report(y_test, y_pred, digits=4, target_names=['None_vishing', 'Vishing'])\n",
    "    print(report)\n",
    "    \n",
    "    # print the confusion matrix\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "        \n",
    "    # save the model\n",
    "    # model.save('models/{}.h5'.format(model_name))\n",
    "    \n",
    "    # save the history\n",
    "    with open('histories/{}.pkl'.format(model_name), 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "    \n",
    "    # save the results\n",
    "    df_results.loc[model_name] = [model_f1_score, model_precision, model_recall, accuracy, training_time]\n",
    "    # df_results.loc[model_name] = [f1_score(y_test, y_pred), precision_score(y_test, y_pred), recall_score(y_test, y_pred), accuracy, training_time]  \n",
    "    \n",
    "    # print the results\n",
    "    # df_results\n",
    "    \n",
    "    return model, history, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9ebd0d0a19b6e6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build, train and evaluate the stacked BiLSTM model\n",
    "model_name = augmented_dataset + '_stackedBiLSTM'\n",
    "model_stackedbilstm, history_stackedbilstm, report_stackedbilstm = build_train_stackedbilstm_model(model_name, X_train_pad, y_train, X_val_pad, y_val, X_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1647903d69f31441",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dc8845b6355089",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the confusion matrix\n",
    "plot_name = augmented_dataset + '_stackedBiLSTM_Classification_report'\n",
    "plot_classification_report(report_stackedbilstm, plot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d01f5ed87f5e052",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the training and validation loss and accuracy\n",
    "plot_name = augmented_dataset + '_stackedBiLSTM'\n",
    "plot_loss_accuracy(history_stackedbilstm, plot_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b792de0f8c653b70",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Stacked BiLSTM layer with FastText embedding layer with FastText embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7431551ecc4052b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build, train and evaluate the stacked BiLSTM model with FastText embedding layer\n",
    "model_name = augmented_dataset + '_stackedBiLSTM_FT'\n",
    "model_stackedbilstm_ft, history_stackedbilstm_ft, report_stackedbilstm_ft = build_train_stackedbilstm_model(model_name, X_train_pad, y_train, X_val_pad, y_val, X_test_pad, y_test, embedding_matrix=embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6577c6cbfdc80061",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3060a6c551616415",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the confusion matrix\n",
    "plot_name = augmented_dataset + '_stackedBiLSTM_FT_Classification_report'\n",
    "plot_classification_report(report_stackedbilstm_ft, plot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603af0c3545bb189",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the training and validation loss and accuracy\n",
    "plot_name = augmented_dataset + '_stackedBiLSTM_FT'\n",
    "plot_loss_accuracy(history_stackedbilstm_ft, plot_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644138f74d12dc05",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1D CNN Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d9ff8466157f3b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to build, train and evaluate the stacked BiLSTM model\n",
    "def build_train_cnn_model(model_name, X_train, y_train, X_val, y_val, X_test, y_test, epochs=epochs, batch_size=batch_size, learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate, embedding_matrix=None):\n",
    "    \n",
    "    # define the model architecture\n",
    "    model = Sequential()\n",
    "    # check if the embedding_matrix is None or not\n",
    "    if embedding_matrix is None:\n",
    "        model.add(Embedding(max_words, embedding_dim, input_length=max_len, trainable=False))\n",
    "    else:\n",
    "        model.add(Embedding(max_words, embedding_dim, weights= [embedding_matrix], input_length=max_len, trainable=False))\n",
    "\n",
    "    model.add(SpatialDropout1D(spa_dropout_ratio))\n",
    "    model.add(Conv1D(num_filters, kernel_size, activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling1D())\n",
    "    # model.add(GlobalMaxPooling1D()) #takes the maximum value over the time dimension from each feature map generated by the convolutional layers, Dimensionality Reduction, Reduces Overfitting\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    model.add(Flatten()) # no need if used Global poooling\n",
    "    model.add(Dropout(dropout_ratio))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification\n",
    "    \n",
    "    # compile the model\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=learning_rate,\n",
    "    decay_steps=decay_steps,\n",
    "    decay_rate=decay_rate\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        # optimizer=Adam(learning_rate=learning_rate, decay=learning_rate / decay_steps),\n",
    "        optimizer = Adam(learning_rate=lr_schedule),\n",
    "        loss='binary_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # print the model summary\n",
    "    print(model.summary())\n",
    "    print('#' * 150)\n",
    "    \n",
    "    # Create a callback that saves the best model during validation\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        \"models/\" + model_name + \"_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \".h5\",\n",
    "        # \"models/BiLSTM_\"+ datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \".h5\",\n",
    "        monitor='val_accuracy', # val_loss or val_accuracy \n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='max' # max for val_accuracy, min for val_lossmode='mn'\n",
    "    )\n",
    "    # EarlyStopping to stop training when the validation loss has stopped improving\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        verbose = 1,\n",
    "        patience = 3, # Number of epochs with no improvement after which training will be stopped.\n",
    "        mode = 'min'\n",
    "    )\n",
    "\n",
    "    # TensorBoard for visualization\n",
    "    log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    # train the model\n",
    "    start_time = time()\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1,\n",
    "        callbacks=[model_checkpoint, early_stopping, tensorboard_callback]\n",
    "    )\n",
    "    end_time = time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    # print the training time\n",
    "    print('Training time: {}'.format(training_time))\n",
    "    \n",
    "    # evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print('Test Loss: {}'.format(loss))\n",
    "    print('Test Accuracy: {}'.format(accuracy))\n",
    "    \n",
    "    # predict the test set\n",
    "    # y_pred = model.predict(X_test)\n",
    "    # y_pred = np.argmax(y_pred, axis=1)\n",
    "    # y_test = np.argmax(y_test, axis=1)\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred = (y_pred_probs >= 0.5).astype(int)  # Convert probabilities to binary (0 or 1)\n",
    "    \n",
    "    # print the precision, recall and f1-score\n",
    "    model_precision = precision_score(y_test, y_pred)\n",
    "    model_recall = recall_score(y_test, y_pred)\n",
    "    model_f1_score = f1_score(y_test, y_pred)\n",
    "    print('Precision: {}'.format(model_precision))\n",
    "    print('Recall: {}'.format(model_recall))\n",
    "    print('F1-score: {}'.format(model_f1_score))\n",
    "        \n",
    "    # print the classification report\n",
    "    report = classification_report(y_test, y_pred, digits=4, target_names=['None_vishing', 'Vishing'])\n",
    "    print(report)\n",
    "    \n",
    "    # print the confusion matrix\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "        \n",
    "    # save the model\n",
    "    # model.save('models/{}.h5'.format(model_name))\n",
    "    \n",
    "    # save the history\n",
    "    with open('histories/{}.pkl'.format(model_name), 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "    \n",
    "    # save the results\n",
    "    df_results.loc[model_name] = [model_f1_score, model_precision, model_recall, accuracy, training_time]\n",
    "    # df_results.loc[model_name] = [f1_score(y_test, y_pred), precision_score(y_test, y_pred), recall_score(y_test, y_pred), accuracy, training_time]  \n",
    "    \n",
    "    # print the results\n",
    "    # df_results\n",
    "    \n",
    "    return model, history, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ecdbbbddbda051",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build, train and evaluate the CNN model\n",
    "model_name = augmented_dataset + '_CNN'\n",
    "model_cnn, history_cnn, report_cnn = build_train_cnn_model(model_name, X_train_pad, y_train, X_val_pad, y_val, X_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8af77ae212f81f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10decec3d4c35c30",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the confusion matrix\n",
    "plot_name = augmented_dataset + '_CNN_Classification_report'\n",
    "plot_classification_report(report_cnn, plot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d62ba137865277",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the training and validation loss and accuracy\n",
    "plot_name = augmented_dataset + '_CNN'\n",
    "plot_loss_accuracy(history_cnn, plot_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ece3f13710d321",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1D CNN layer with FastText embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce283fe86fe559",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build, train and evaluate the CNN model with FastText embedding layer\n",
    "model_name = augmented_dataset + '_CNN_FT'\n",
    "model_cnn_ft, history_cnn_ft, report_cnn_ft = build_train_cnn_model(model_name, X_train_pad, y_train, X_val_pad, y_val, X_test_pad, y_test, embedding_matrix=embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9905c61d2601dc2d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b154446fe74de678",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the confusion matrix\n",
    "plot_name = augmented_dataset + '_CNN_FT_Classification_report'\n",
    "plot_classification_report(report_cnn_ft, plot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24ca6653996b3a0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the training and validation loss and accuracy\n",
    "plot_name = augmented_dataset + '_CNN_FT'\n",
    "plot_loss_accuracy(history_cnn_ft, plot_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931052dd7304b432",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1D CNN layer with multiple kernel sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc126155546835b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to build, train and evaluate the 1D CNN layer with multiple kernel sizes model\n",
    "def build_train_cnn_multiple_model(model_name, X_train, y_train, X_val, y_val, X_test, y_test, epochs=epochs, batch_size=batch_size, learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate, embedding_matrix=None):\n",
    "    \n",
    "    # define the model architecture\n",
    "    model = Sequential()\n",
    "    # check if the embedding_matrix is None or not\n",
    "    if embedding_matrix is None:\n",
    "        model.add(Embedding(max_words, embedding_dim, input_length=max_len, trainable=False))\n",
    "    else:\n",
    "        model.add(Embedding(max_words, embedding_dim, weights= [embedding_matrix], input_length=max_len, trainable=False))\n",
    "\n",
    "    model.add(SpatialDropout1D(spa_dropout_ratio))\n",
    "    model.add(Conv1D(num_filters, kernel_size, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Conv1D(num_filters, kernel_size+1, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Conv1D(num_filters, kernel_size+2, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D())\n",
    "    # model.add(GlobalMaxPooling1D()) #takes the maximum value over the time dimension from each feature map generated by the convolutional layers, Dimensionality Reduction, Reduces Overfitting\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    model.add(Flatten()) # no need if used Global poooling\n",
    "    model.add(Dropout(dropout_ratio))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification\n",
    "\n",
    "    # compile the model\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=learning_rate,\n",
    "        decay_steps=decay_steps,\n",
    "        decay_rate=decay_rate\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        # optimizer=Adam(learning_rate=learning_rate, decay=learning_rate / decay_steps),\n",
    "        optimizer=Adam(learning_rate=lr_schedule),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # print the model summary\n",
    "    print(model.summary())\n",
    "    print('#' * 150)\n",
    "\n",
    "    # Create a callback that saves the best model during validation\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        \"models/\" + model_name + \"_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \".h5\",\n",
    "        # \"models/BiLSTM_\"+ datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \".h5\",\n",
    "        monitor='val_accuracy',  # val_loss or val_accuracy \n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='max'  # max for val_accuracy, min for val_lossmode='mn'\n",
    "    )\n",
    "    # EarlyStopping to stop training when the validation loss has stopped improving\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        verbose=1,\n",
    "        patience=3,  # Number of epochs with no improvement after which training will be stopped.\n",
    "        mode='min'\n",
    "    )\n",
    "\n",
    "    # TensorBoard for visualization\n",
    "    log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    # train the model\n",
    "    start_time = time()\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1,\n",
    "        callbacks=[model_checkpoint, early_stopping, tensorboard_callback]\n",
    "    )\n",
    "    end_time = time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    # print the training time\n",
    "    print('Training time: {}'.format(training_time))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print('Test Loss: {}'.format(loss))\n",
    "    print('Test Accuracy: {}'.format(accuracy))\n",
    "\n",
    "    # predict the test set\n",
    "    # y_pred = model.predict(X_test)\n",
    "    # y_pred = np.argmax(y_pred, axis=1)\n",
    "    # y_test = np.argmax(y_test, axis=1)\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred = (y_pred_probs >= 0.5).astype(int)  # Convert probabilities to binary (0 or 1)\n",
    "\n",
    "    # print the precision, recall and f1-score\n",
    "    model_precision = precision_score(y_test, y_pred)\n",
    "    model_recall = recall_score(y_test, y_pred)\n",
    "    model_f1_score = f1_score(y_test, y_pred)\n",
    "    print('Precision: {}'.format(model_precision))\n",
    "    print('Recall: {}'.format(model_recall))\n",
    "    print('F1-score: {}'.format(model_f1_score))\n",
    "\n",
    "    # print the classification report\n",
    "    report = classification_report(y_test, y_pred, digits=4, target_names=['None_vishing', 'Vishing'])\n",
    "    print(report)\n",
    "\n",
    "    # print the confusion matrix\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # save the model\n",
    "    # model.save('models/{}.h5'.format(model_name))\n",
    "\n",
    "    # save the history\n",
    "    with open('histories/{}.pkl'.format(model_name), 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "\n",
    "    # save the results\n",
    "    df_results.loc[model_name] = [model_f1_score, model_precision, model_recall, accuracy, training_time]\n",
    "    # df_results.loc[model_name] = [f1_score(y_test, y_pred), precision_score(y_test, y_pred), recall_score(y_test, y_pred), accuracy, training_time]  \n",
    "\n",
    "    # print the results\n",
    "    # df_results\n",
    "\n",
    "    return model, history, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc64605784bbe6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build, train and evaluate the CNN with mulitple kernel sizes model\n",
    "model_name = augmented_dataset + '_CNN_multiple'\n",
    "model_cnn_multiple, history_cnn_multiple, report_cnn_multiple = build_train_cnn_multiple_model(model_name, X_train_pad, y_train, X_val_pad, y_val, X_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193a58ba2acd26a7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4a657cf8d221cf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the confusion matrix\n",
    "plot_name = augmented_dataset + '_CNN_multiple_Classification_report'\n",
    "plot_classification_report(report_cnn_multiple, plot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01907d1c8d0c472",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the training and validation loss and accuracy\n",
    "plot_name = augmented_dataset + '_CNN_multiple'\n",
    "plot_loss_accuracy(history_cnn_multiple, plot_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d004131060eb0d92",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1D CNN layer with multiple kernel sizes with FastText embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7546a459ef600855",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build, train and evaluate the CNN with multiple kernel sizes model with FastText embedding layer\n",
    "model_name = augmented_dataset + '_CNN_multiple_FT'\n",
    "model_cnn_multiple_ft, history_cnn_multiple_ft, report_cnn_multiple_ft = build_train_cnn_multiple_model(model_name, X_train_pad, y_train, X_val_pad, y_val, X_test_pad, y_test, embedding_matrix=embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f795e7550352d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240639395d76b2a7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the confusion matrix\n",
    "plot_name = augmented_dataset + '_CNN_multiple_FT_Classification_report'\n",
    "plot_classification_report(report_cnn_multiple_ft, plot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f4fbf4c4f72a86",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the training and validation loss and accuracy\n",
    "plot_name = augmented_dataset + '_CNN_multiple_FT'\n",
    "plot_loss_accuracy(history_cnn_multiple_ft, plot_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e92f6ad018a254",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## save the results in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7037ddc7157dbb8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the training results\n",
    "df_results.to_csv(\"reports/\" + augmented_dataset+ \" _Models_performance_summary_\" + datetime.now().strftime(\"%Y%m%d_%H-%M-%S\") + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d2cbfe59f8ff0a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot all the models performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78384625e1f3c4b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot overall accuracy on test set\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "plt.plot(history_lstm.epoch, history_lstm.history['val_accuracy'], '-o', label='lstm')\n",
    "plt.plot(history_lstm_ft.epoch, history_lstm_ft.history['val_accuracy'], '-o', label='lstm_ft')\n",
    "plt.plot(history_stackedlstm.epoch, history_stackedlstm.history['val_accuracy'], '-o', label='stackedlstm')\n",
    "plt.plot(history_stackedlstm_ft.epoch, history_stackedlstm_ft.history['val_accuracy'], '-o', label='stackedlstm_ft')\n",
    "plt.plot(history_bilstm.epoch, history_bilstm.history['val_accuracy'], '-o', label='bilstm')\n",
    "plt.plot(history_bilstm_ft.epoch, history_bilstm_ft.history['val_accuracy'], '-o', label='bilstm_ft')\n",
    "plt.plot(history_stackedbilstm.epoch, history_stackedbilstm.history['val_accuracy'], '-o', label='stackedbilstm')\n",
    "plt.plot(history_stackedbilstm_ft.epoch, history_stackedbilstm_ft.history['val_accuracy'], '-o', label='stackedbilstm_ft')\n",
    "plt.plot(history_cnn.epoch, history_cnn.history['val_accuracy'], '-o', label='cnn')\n",
    "plt.plot(history_cnn_ft.epoch,history_cnn_ft.history['val_accuracy'], '-o', label='cnn_ft')\n",
    "plt.plot(history_cnn_multiple.epoch, history_cnn_multiple.history['val_accuracy'], '-o', label='cnn_multiple')\n",
    "plt.plot(history_cnn_multiple_ft.epoch, history_cnn_multiple_ft.history['val_accuracy'], '-o', label='cnn_multiple_ft')\n",
    "plt.title(augmented_dataset+'_Validation Accuracy of All Models')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xlim(left=0)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig('reports/'+augmented_dataset+'_All_models_accuracy_metrics_'+ datetime.now().strftime(\"%Y%m%d_%H-%M-%S\") + '.png', dpi=600, format='png', bbox_inches='tight')\n",
    "plt.savefig('reports/'+augmented_dataset+'_All_models_accuracy_metrics_'+ datetime.now().strftime(\"%Y%m%d_%H-%M-%S\") + '.pdf', dpi=600, format='pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb5f582b134032e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot overall looss on test set\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "plt.plot(history_lstm.epoch, history_lstm.history['val_loss'], '-o', label='lstm')\n",
    "plt.plot(history_lstm_ft.epoch, history_lstm_ft.history['val_loss'], '-o', label='lstm_ft')\n",
    "plt.plot(history_stackedlstm.epoch, history_stackedlstm.history['val_loss'], '-o', label='stackedlstm')\n",
    "plt.plot(history_stackedlstm_ft.epoch, history_stackedlstm_ft.history['val_loss'], '-o', label='stackedlstm_ft')\n",
    "plt.plot(history_bilstm.epoch, history_bilstm.history['val_loss'], '-o', label='bilstm')\n",
    "plt.plot(history_bilstm_ft.epoch, history_bilstm_ft.history['val_loss'], '-o', label='bilstm_ft')\n",
    "plt.plot(history_stackedbilstm.epoch, history_stackedbilstm.history['val_loss'], '-o', label='stackedbilstm')\n",
    "plt.plot(history_stackedbilstm_ft.epoch, history_stackedbilstm_ft.history['val_loss'], '-o', label='stackedbilstm_ft')\n",
    "plt.plot(history_cnn.epoch, history_cnn.history['val_loss'], '-o', label='cnn')\n",
    "plt.plot(history_cnn_ft.epoch, history_cnn_ft.history['val_loss'], '-o', label='cnn_ft')\n",
    "plt.plot(history_cnn_multiple.epoch, history_cnn_multiple.history['val_loss'], '-o', label='cnn_multiple')\n",
    "plt.plot(history_cnn_multiple_ft.epoch, history_cnn_multiple_ft.history['val_loss'], '-o', label='cnn_multiple_ft')\n",
    "plt.title(augmented_dataset+'_Validation Loss of All Models')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xlim(left=0)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig('reports/'+augmented_dataset+'_All_models_val_loss_metrics_'+ datetime.now().strftime(\"%Y%m%d_%H-%M-%S\") + '.png', dpi=600, format='png', bbox_inches='tight')\n",
    "plt.savefig('reports/'+augmented_dataset+'_All_models_val_loss_metrics_'+ datetime.now().strftime(\"%Y%m%d_%H-%M-%S\") + '.pdf', dpi=600, format='pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960dd06a-7766-46ee-9a32-28f5e306e2f7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
